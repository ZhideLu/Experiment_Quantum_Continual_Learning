{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33deeca1",
   "metadata": {},
   "source": [
    "# Learning the quantum engineered task and the classical task using                classical feedforward neural networks (FFNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c018e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Yao, YaoPlots, Plots\n",
    "using LinearAlgebra, Statistics, Random, StatsBase, MAT, Printf \n",
    "using Flux: batch, Flux \n",
    "using MultivariateStats, StatsBase, Statistics \n",
    "using Zygote\n",
    "using DataFrames \n",
    "using JLD\n",
    "include(\"../functions/Function_QCL.jl\") ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf56eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecb765dc",
   "metadata": {},
   "source": [
    "# Quantum engineered task\n",
    "\n",
    "## The ground truth label of each input sample is determined by a local observable                  evolved under a quantum circuit with randomly chosen gate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubit = 10 ;\n",
    "depth = 3 ;\n",
    "\n",
    "mid = 1 ;\n",
    "\n",
    "op0 = put(num_qubit, mid=>0.5*(I2+Z)) ;\n",
    "op1 = put(num_qubit, mid=>0.5*(I2-Z)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dim = num_qubit ; # choose principal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7526d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 1000 ;\n",
    "num_test = 200 ;\n",
    "\n",
    "data1 = matread(\"../dataset/FashionMNIST_0-9.mat\")\n",
    "x_train_1 = real(data1[\"x_train\"][ :, 1 : num_train ]) ; \n",
    "y_train_1 = data1[\"y_train\"][ 1 : num_train, : ] ;\n",
    "x_test_1 = real(data1[\"x_test\"][ :, 1 : num_test ] ) ;  \n",
    "y_test_1 = data1[\"y_test\"][ 1 : num_test, : ]  ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = hcat( x_train_1, x_test_1 ) ;\n",
    "\n",
    "# PCA \n",
    "pca_model = fit(PCA, x_all, maxoutdim = pca_dim) ;\n",
    "trans_X = MultivariateStats.transform(pca_model, x_all) ;\n",
    "X_std = std( trans_X, dims = 2 ) ; trans_X = trans_X ./ X_std ;  # normalize\n",
    "\n",
    "# encoding to Rzz gate\n",
    "trans_X_1 = zeros(pca_dim-1, size(x_all)[2])\n",
    "\n",
    "for i in 1 : pca_dim-1\n",
    "    trans_X_1[i, :] =  4 .* trans_X[i, :] .* trans_X[i+1, :]\n",
    "end\n",
    "\n",
    "# two layers of encoding\n",
    "XX = vcat(trans_X, trans_X_1, trans_X, trans_X_1)\n",
    "\n",
    "trans_x_train_1 = XX[ :, 1 : num_train] ;\n",
    "trans_x_test_1 = XX[ :, num_train+1 : end] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff32f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_1(nbit::Int64) = chain( H_chain(nbit),  rz_layer(nbit, 1:nbit) ) ;\n",
    "chain_2(nbit::Int64) = chain( nbit, chain( control(i,i+1=>X), put(i+1 => Rz(0)), control(i,i+1=>X) ) \n",
    "                                       for i in 1 : nbit-1) ;\n",
    "\n",
    "circuit_encoding(nbit::Int64)  = chain( chain_1(nbit), chain_2(nbit), chain_1(nbit), chain_2(nbit) ) ;\n",
    "circuit_encoding_2(nbit::Int64)  = chain( rx_layer(nbit, 1:nbit), ent_cx(nbit, 1:nbit) )  ;\n",
    "\n",
    "circuit_variational(nbit::Int64, depth)  = chain( chain(nbit, params_layer(nbit, 1:nbit), \n",
    "                       ent_cz(nbit, 1:nbit)) for _ in 1 : depth ) ;\n",
    "\n",
    "circuit = chain( circuit_encoding(num_qubit), circuit_variational(num_qubit, depth) ) ;\n",
    "dim = nparameters(circuit) ;\n",
    "YaoPlots.plot(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702179a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_params = matread(\"target_params_10.mat\")[\"target_params\"] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a2f10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec413393",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cir_1 = [ chain( circuit_encoding(num_qubit), circuit_variational(num_qubit, depth) )   \n",
    "    for _ in 1 : num_train] ;\n",
    "\n",
    "test_cir_1  = [ chain( circuit_encoding(num_qubit), circuit_variational(num_qubit, depth) )  \n",
    "    for _ in 1 : num_test] ;\n",
    "\n",
    "for i in 1 : num_train\n",
    "    dispatch!( train_cir_1[i], vcat( trans_x_train_1[:, i], target_params ) ) ;\n",
    "end\n",
    "\n",
    "for i in 1 : num_test\n",
    "    dispatch!(test_cir_1[i], vcat( trans_x_test_1[:, i], target_params )) ;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_train = zeros(num_train, 2) ;\n",
    "for i = 1 : num_train\n",
    "    res = zero_state(num_qubit) |> train_cir_1[i]\n",
    "    rdm = density_matrix(res, (mid))\n",
    "    q_train[i,:] = rdm |> probs\n",
    "end\n",
    "\n",
    "y_train_1_re = zeros(num_train, 2) ;\n",
    "\n",
    "for i in 1 : num_train\n",
    "    if q_train[i, 1] < 0.5\n",
    "        y_train_1_re[ i, : ] = [0 , 1]\n",
    "    else\n",
    "        y_train_1_re[ i, : ] = [1 , 0]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f74d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q_test = zeros(num_test, 2) ;\n",
    "\n",
    "for i = 1 : num_test\n",
    "    res = zero_state(num_qubit) |> test_cir_1[i]\n",
    "    rdm = density_matrix(copy(res), (mid))\n",
    "    q_test[i, :] = rdm |> probs\n",
    "end\n",
    "\n",
    "y_test_1_re = zeros(num_test, 2) ;\n",
    "\n",
    "for i in 1 : num_test\n",
    "    if q_test[i, 1] < 0.5\n",
    "        y_test_1_re[ i, : ] = [0 , 1]\n",
    "    else\n",
    "        y_test_1_re[ i, : ] = [1 , 0]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055f2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "@show  sum( abs(q_train[i,1] - q_train[i,2]) >=0.2 for i in 1:num_train )\n",
    "@show  sum( (q_train[i,1] - q_train[i,2]) >=0.2 for i in 1:num_train )\n",
    "@show  sum( (q_train[i,1] - q_train[i,2]) < -0.2 for i in 1:num_train )\n",
    "@show  sum( abs(q_test[i,1] - q_test[i,2]) >=0.2 for i in 1:num_test )\n",
    "@show  sum( (q_test[i,1] - q_test[i,2]) >=0.2 for i in 1:num_test )\n",
    "@show  sum( (q_test[i,1] - q_test[i,2]) < -0.2 for i in 1:num_test ) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905f95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_test = [i for i in 1:num_test if abs(q_test[i, 1] - q_test[i, 2]) >= 0.2] ;\n",
    "index_train = [i for i in 1:num_train if abs(q_train[i, 1] - q_train[i, 2]) >= 0.2]  ;\n",
    "\n",
    "num_train_re = length(index_train) ;  num_test_re = length(index_test) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14238e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the data with abs(<Z>) > 0.1 as the dataset\n",
    "se_y_test_1_re = y_test_1_re[index_test, :]  ;\n",
    "se_y_train_1_re = y_train_1_re[index_train, :] ;\n",
    "\n",
    "se_y_train_1 = y_train_1[index_train, :] ;\n",
    "se_y_test_1 = y_test_1[index_test, :] ;\n",
    "\n",
    "quantum_trans_x_train_1 = trans_x_train_1[:, index_train] ;\n",
    "quantum_trans_x_test_1 = trans_x_test_1[:, index_test] ;\n",
    "\n",
    "classical_x_train_1 = quantum_trans_x_train_1[1 : pca_dim , :]\n",
    "classical_x_test_1 = quantum_trans_x_test_1[1 : pca_dim , :] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e248d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c4a4451",
   "metadata": {},
   "source": [
    "# Classical task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_2 = chain( circuit_encoding_2(num_qubit), circuit_variational(num_qubit, depth) ) ;\n",
    "dim_2 = nparameters(circuit_2) ;\n",
    "YaoPlots.plot(circuit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c3e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_2 = 500 ;\n",
    "num_test_2 = 100 ;\n",
    "\n",
    "# pca 处理\n",
    "data2 = matread(\"../dataset/MedNIST_hand_breast_wk.mat\")\n",
    "\n",
    "x_train_2 = real(data2[\"x_train\"][ :, 1 : num_train_2 ]) ; \n",
    "y_train_2 = data2[\"y_train\"][ 1 : num_train_2, : ] ;\n",
    "x_test_2 = real(data2[\"x_test\"][ :, 1 : num_test_2 ] ) ;  \n",
    "y_test_2 = data2[\"y_test\"][ 1 : num_test_2, : ]  ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_2 = hcat( x_train_2, x_test_2 ) ;\n",
    "\n",
    "# PCA \n",
    "pca_model_2 = fit(PCA, x_all_2, maxoutdim = pca_dim) ;\n",
    "trans_X_ = MultivariateStats.transform(pca_model_2, x_all_2) ;\n",
    "X_std_2 = std( trans_X_, dims = 2 ) ; trans_X_ = trans_X_ ./ X_std_2 ;  # normalize\n",
    "\n",
    "x_train_2 =  trans_X_[:, 1 : num_train_2]\n",
    "x_test_2 =  trans_X_[:, num_train_2+1 : end] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7f2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd3b1eaf",
   "metadata": {},
   "source": [
    "# Learning using classical FFNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12606e5",
   "metadata": {},
   "source": [
    "## Defining some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss(x, y) = Flux.crossentropy(vcat(model_1(x ), 1 .- model_1(x )) , y)\n",
    "\n",
    "function acc(x, y)\n",
    "    y_pred = [ t[1] for t in argmax( vcat(model_1(x), 1 .- model_1(x)),  dims =1 ) ]\n",
    "    y_true = [ t[1] for t in argmax( y,  dims =1 ) ] ;\n",
    "\n",
    "    return sum(y_pred .== y_true) / size(x, 2)\n",
    "\n",
    "end\n",
    "\n",
    "loss_2(x, y) = Flux.crossentropy(vcat(model_1(x ), 1 .- model_1(x )) , y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantum engineered task\n",
    "function learning_1(lr1, epochs1)\n",
    "    \n",
    "    c_history_loss_train_1nd_1 = Float64[]\n",
    "    c_history_acc_train_1nd_1 = Float64[]\n",
    "    c_history_loss_test_1nd_1 = Float64[] ;\n",
    "    c_history_acc_test_1nd_1 = Float64[] ;\n",
    "    \n",
    "    lr1 = 0.05\n",
    "    opt = Flux.ADAM(lr1)\n",
    "\n",
    "    data_batch = Flux.Data.DataLoader((classical_x_train_1, se_y_train_1_re'), batchsize = 25, shuffle=true ) \n",
    "\n",
    "    for k in 1 : epochs1\n",
    "\n",
    "        loss_train_1nd_1 = loss(classical_x_train_1, se_y_train_1_re') ;  acc_train_1nd_1 = acc(classical_x_train_1, se_y_train_1_re')\n",
    "        loss_test_1nd_1 = loss(classical_x_test_1, se_y_test_1_re') ;   acc_test_1nd_1 = acc(classical_x_test_1, se_y_test_1_re')\n",
    "        push!( c_para_1_history, deepcopy(ps))  \n",
    "        \n",
    "        push!(c_history_loss_train_1nd_1, loss_train_1nd_1 ) ;   push!(c_history_acc_train_1nd_1, acc_train_1nd_1) \n",
    "        push!(c_history_loss_test_1nd_1, loss_test_1nd_1) ;   push!(c_history_acc_test_1nd_1, acc_test_1nd_1)\n",
    "\n",
    "#         @printf(\"\\nStep=%d, train_loss=%.3f, train_acc=%.3f\\n\", k, loss_train_1nd_1, acc_train_1nd_1)\n",
    "#         @printf(\"\\nStep=%d, test_loss=%.3f, test_acc=%.3f\\n\", k, loss_test_1nd_1, acc_test_1nd_1)\n",
    "\n",
    "        Flux.train!(loss, ps, data_batch, opt)\n",
    "    end\n",
    "    \n",
    "    c_history_loss_train_1nd_1, c_history_acc_train_1nd_1, c_history_loss_test_1nd_1, c_history_acc_test_1nd_1, c_para_1_history \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_para_1_history[end]\n",
    "# ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fisher_matrix\n",
    "function Fisher(ps)\n",
    "    \n",
    "    g = Flux.gradient(() -> loss(classical_x_train_1[:, 1], se_y_train_1_re'[:, 1]), ps)\n",
    "    fisher_t = copy(g) ;\n",
    "    [ fisher_t[ ps[i] ] .= 0 for i in 1 : length(ps) ] ;\n",
    "\n",
    "    for i in 1 : num_train_re\n",
    "        grads = Flux.gradient(() -> loss(classical_x_train_1[:, i], se_y_train_1_re'[:, i]), ps)\n",
    "        fisher_ = copy(grads) ;\n",
    "        [ fisher_[ ps[i] ] = fisher_[ ps[i] ] .^ 2  for i in 1 : length(ps) ] ;\n",
    "\n",
    "        fisher_t .+= fisher_\n",
    "    end\n",
    "    fisher_t  = fisher_t ./ num_train_re\n",
    "    \n",
    "    fisher_t\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fisher_t[ps[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical task\n",
    "function learning_2(lr2, epochs2, lambda2, fisher_t, c_para_1_history )\n",
    "    \n",
    "    c_history_acc_train_2nd_2 = Float64[] ;   c_history_acc_test_2nd_2 = Float64[] ;\n",
    "    c_history_loss_train_2nd_2 = Float64[] ;   c_history_loss_test_2nd_2 = Float64[] ;\n",
    "\n",
    "    c_history_acc_test_2nd_1 = Float64[] ;   c_history_loss_test_2nd_1 = Float64[] ;\n",
    "    c_history_acc_train_2nd_1 = Float64[] ;   c_history_loss_train_2nd_1 = Float64[] ;\n",
    "    \n",
    "    lr2 = 0.05\n",
    "    opt2 = Flux.ADAM(lr2)\n",
    "\n",
    "    data_batch2 = Flux.Data.DataLoader((x_train_2, y_train_2'), batchsize = 25, shuffle=true ) \n",
    "\n",
    "    for k in 1 : epochs2\n",
    "\n",
    "        loss_train_2nd_2 = loss_2(x_train_2, y_train_2') ;   acc_train_2nd_2 = acc(x_train_2, y_train_2')\n",
    "        loss_test_2nd_2 = loss_2(x_test_2, y_test_2') ;   acc_test_2nd_2 = acc(x_test_2, y_test_2')\n",
    "\n",
    "        loss_train_2nd_1 = loss(classical_x_train_1, se_y_train_1_re') ;  acc_train_2nd_1 = acc(classical_x_train_1, se_y_train_1_re')\n",
    "        loss_test_2nd_1 = loss(classical_x_test_1, se_y_test_1_re') ;   acc_test_2nd_1 = acc(classical_x_test_1, se_y_test_1_re')\n",
    "\n",
    "        push!(c_history_acc_train_2nd_2, acc_train_2nd_2) ;    push!(c_history_loss_train_2nd_2, loss_train_2nd_2) ;   \n",
    "        push!(c_history_acc_test_2nd_2, acc_test_2nd_2) ;    push!(c_history_loss_test_2nd_2, loss_test_2nd_2) ;   \n",
    "\n",
    "        push!(c_history_acc_train_2nd_1, acc_train_2nd_1) ;    push!(c_history_loss_train_2nd_1, loss_train_2nd_1) ;  \n",
    "        push!(c_history_acc_test_2nd_1, acc_test_2nd_1) ;    push!(c_history_loss_test_2nd_1, loss_test_2nd_1) ;  \n",
    "\n",
    "\n",
    "#         @printf(\"Step=%d, train_loss=%.3f, train_acc=%.3f\\n\", k, loss_train_2nd_2, acc_train_2nd_2)\n",
    "#         @printf(\"Step=%d, test_loss=%.3f, test_acc=%.3f\\n\", k, loss_test_2nd_2, acc_test_2nd_2)\n",
    "\n",
    "#         @printf(\"train_task1, loss=%.3f, acc=%.3f\\n\", loss_train_2nd_1, acc_train_2nd_1)\n",
    "#         @printf(\"task1, loss=%.3f, acc=%.3f\\n\", loss_test_2nd_1, acc_test_2nd_1)\n",
    "\n",
    "\n",
    "        for (x, y) in data_batch2\n",
    "            grads = Flux.gradient(() -> loss_2(x, y), ps)\n",
    "\n",
    "            for i in 1 : length(ps)\n",
    "                grads[ps[i]] = grads[ps[i]] + lambda2 * fisher_t[ps[i]] .* (ps[i]  - c_para_1_history[end][i])\n",
    "            end\n",
    "\n",
    "            Flux.update!(Flux.Adam(lr2), ps, grads)\n",
    "\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    c_history_acc_train_2nd_2, c_history_acc_test_2nd_2, c_history_loss_train_2nd_2, c_history_loss_test_2nd_2, \n",
    "    c_history_acc_test_2nd_1,  c_history_loss_test_2nd_1, c_history_acc_train_2nd_1,  c_history_loss_train_2nd_1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb374c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c885ea7",
   "metadata": {},
   "source": [
    "## Classical learning with different regularization strengths in the EWC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "\n",
    "input_size = size(classical_x_train_1, 1)\n",
    "output_size = 1\n",
    "hidden_size = 20 ;\n",
    "\n",
    "model_1 = Flux.Chain(\n",
    "    Flux.Dense(input_size, hidden_size, Flux.σ; init = Flux.randn ),\n",
    "    Flux.Dense(hidden_size, output_size, Flux.σ; init = Flux.randn),\n",
    ")     |> Flux.f64\n",
    "\n",
    "total_params = sum(length, Flux.params(model_1)) ;\n",
    "@show model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b151c1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = 100 ; C2 = 50 ;\n",
    "learning_results = [Dict() for _ in 1 : C2] ; \n",
    "for R in 1 : C2\n",
    "    \n",
    "    for lambda2 in 0 : 2 : C1\n",
    "\n",
    "        model_1 = Flux.Chain(\n",
    "            Flux.Dense(input_size, hidden_size, Flux.σ; init = Flux.randn ),\n",
    "            Flux.Dense(hidden_size, output_size, Flux.σ; init = Flux.randn ),\n",
    "            )     |> Flux.f64\n",
    "\n",
    "        ps = Flux.params(model_1)\n",
    "\n",
    "        lr1 = 0.05; epochs1 = 20; \n",
    "        lr2 = 0.05; epochs2 = 17; \n",
    "\n",
    "        # learning the 1st task\n",
    "        c_history_loss_train_1nd_1, c_history_acc_train_1nd_1, c_history_loss_test_1nd_1, c_history_acc_test_1nd_1, c_para_1_history = \n",
    "                    learning_1(lr1, epochs1)   ;\n",
    "\n",
    "        ps = Flux.params(model_1)\n",
    "        # fisher information\n",
    "        fisher_t = Fisher(ps) ;\n",
    "\n",
    "        Flux.loadparams!( model_1, c_para_1_history[end] ) ;\n",
    "\n",
    "\n",
    "        # learning the 2nd task\n",
    "\n",
    "        c_history_acc_train_2nd_2, c_history_acc_test_2nd_2, c_history_loss_train_2nd_2, c_history_loss_test_2nd_2, \n",
    "            c_history_acc_test_2nd_1,  c_history_loss_test_2nd_1, c_history_acc_train_2nd_1,  c_history_loss_train_2nd_1 = \n",
    "                      learning_2(lr2, epochs2, lambda2, fisher_t, c_para_1_history)   ;\n",
    "\n",
    "        learning_results[R][string(lambda2)] = \n",
    "        [c_history_loss_train_1nd_1, c_history_acc_train_1nd_1, c_history_loss_test_1nd_1, c_history_acc_test_1nd_1, \n",
    "        c_history_acc_train_2nd_2, c_history_acc_test_2nd_2, c_history_loss_train_2nd_2, c_history_loss_test_2nd_2, \n",
    "        c_history_acc_test_2nd_1,  c_history_loss_test_2nd_1, c_history_acc_train_2nd_1,  c_history_loss_train_2nd_1] ;\n",
    "\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e451c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_results[1][string(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"classical_learning_results.jld\", \"accuracy_loss\", learning_results)\n",
    "# load(\"classical_learning_results.jld\")[\"accuracy_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c20ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "matwrite(\"classical_continual_learning_lambda_40.mat\", Dict(\n",
    "        \"task_1\" =>  vcat(learning_results[1][string(40)][4], learning_results[1][string(40)][9]),\n",
    "        \"task_2\" =>  learning_results[1][string(40)][6]   )\n",
    "        )   ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650fb6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task_2 = mean([[learning_results[j][string(i)][6][end] for i in 0 : 2 : C1] for j in 1:C2]) \n",
    "task_1 = mean([[learning_results[j][string(i)][9][end] for i in 0 : 2 : C1] for j in 1:C2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "matwrite(\"classical_continual_learning_for_all_lambda.mat\", Dict(\n",
    "        \"lambda\" => collect(0 : 2 : C1),\n",
    "        \"task_1\" =>  task_1,\n",
    "        \"task_2\" =>  task_2   )\n",
    "        )\n",
    "# matread(\"../data/advantage/classical_continual_learning_for_all_lambda.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76cdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot( 0 : 2 : C1, task_2 )\n",
    "Plots.plot!( 0 : 2 : C1, task_1 )\n",
    "Plots.plot!( 0 : 2 : C1, (task_2 .+ task_1)/2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_results = load(\"classical_learning_results.jld\")[\"accuracy_loss\"] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9876a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fab68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
