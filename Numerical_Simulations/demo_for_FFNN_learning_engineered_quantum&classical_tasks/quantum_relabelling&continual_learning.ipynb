{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33deeca1",
   "metadata": {},
   "source": [
    "# Learning the quantum engineered task and the classical task using                quantum neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c018e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Yao, YaoPlots, Plots\n",
    "using LinearAlgebra, Statistics, Random, StatsBase, MAT, Printf \n",
    "using Flux: batch, Flux \n",
    "using MultivariateStats, StatsBase, Statistics \n",
    "using Zygote\n",
    "include(\"../functions/Function_QCL.jl\") ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf56eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "628cab36",
   "metadata": {},
   "source": [
    "# Quantum engineered task\n",
    "\n",
    "## The ground truth label of each input sample is determined by a local observable                  evolved under a quantum circuit with randomly chosen gate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubit = 10 ;\n",
    "depth = 3 ;\n",
    "\n",
    "mid = 1 ;\n",
    "\n",
    "op0 = put(num_qubit, mid=>0.5*(I2+Z)) ;\n",
    "op1 = put(num_qubit, mid=>0.5*(I2-Z)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dim = num_qubit ; # choose  principal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7526d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 1000 ;\n",
    "num_test = 200 ;\n",
    "\n",
    "# pca 处理\n",
    "data1 = matread(\"../dataset/FashionMNIST_0-9.mat\")\n",
    "x_train_1 = real(data1[\"x_train\"][ :, 1 : num_train ]) ; \n",
    "y_train_1 = data1[\"y_train\"][ 1 : num_train, : ] ;\n",
    "x_test_1 = real(data1[\"x_test\"][ :, 1 : num_test ] ) ;  \n",
    "y_test_1 = data1[\"y_test\"][ 1 : num_test, : ]  ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9dbed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = hcat( x_train_1, x_test_1 ) ;\n",
    "\n",
    "# PCA \n",
    "pca_model = fit(PCA, x_all, maxoutdim = pca_dim) ;\n",
    "trans_X = MultivariateStats.transform(pca_model, x_all) ;\n",
    "X_std = std( trans_X, dims = 2 ) ; trans_X = trans_X ./ X_std ;  # normalize\n",
    "\n",
    "# encoding to Rzz gate\n",
    "trans_X_1 = zeros(pca_dim-1, size(x_all)[2])\n",
    "\n",
    "for i in 1 : pca_dim-1\n",
    "    trans_X_1[i, :] =  4 .* trans_X[i, :] .* trans_X[i+1, :]\n",
    "end\n",
    "\n",
    "# two layers of encoding\n",
    "XX = vcat(trans_X, trans_X_1, trans_X, trans_X_1)\n",
    "\n",
    "trans_x_train_1 = XX[ :, 1 : num_train] ;\n",
    "trans_x_test_1 = XX[ :, num_train+1 : end] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b51a417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_1(nbit::Int64) = chain( H_chain(nbit),  rz_layer(nbit, 1:nbit) ) ;\n",
    "chain_2(nbit::Int64) = chain( nbit, chain( control(i,i+1=>X), put(i+1 => Rz(0)), control(i,i+1=>X) ) \n",
    "                               for i in 1 : nbit-1) ;\n",
    "\n",
    "circuit_encoding(nbit::Int64)  = chain( chain_1(nbit), chain_2(nbit), chain_1(nbit), chain_2(nbit) ) ;\n",
    "circuit_encoding_2(nbit::Int64)  = chain( rx_layer(nbit, 1:nbit), ent_cx(nbit, 1:nbit) )  ;\n",
    "\n",
    "circuit_variational(nbit::Int64, depth)  = chain( chain(nbit, params_layer(nbit, 1:nbit), \n",
    "                                 ent_cz(nbit, 1:nbit)) for _ in 1 : depth ) ;\n",
    "\n",
    "circuit = chain( circuit_encoding(num_qubit), circuit_variational(num_qubit, depth) ) ;\n",
    "dim = nparameters(circuit) ;\n",
    "YaoPlots.plot(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d4d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_params = matread(\"target_params_10.mat\")[\"target_params\"] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a2f10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec413393",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cir_1 = [ chain( circuit_encoding(num_qubit), circuit_variational(num_qubit, depth) )   \n",
    "    for _ in 1 : num_train] ;\n",
    "\n",
    "test_cir_1  = [ chain( circuit_encoding(num_qubit), circuit_variational(num_qubit, depth) )  \n",
    "    for _ in 1 : num_test] ;\n",
    "\n",
    "for i in 1 : num_train\n",
    "    dispatch!( train_cir_1[i], vcat( trans_x_train_1[:, i], target_params ) ) ;\n",
    "end\n",
    "\n",
    "for i in 1 : num_test\n",
    "    dispatch!(test_cir_1[i], vcat( trans_x_test_1[:, i], target_params )) ;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_train = zeros(num_train, 2) ;\n",
    "for i = 1 : num_train\n",
    "    res = zero_state(num_qubit) |> train_cir_1[i]\n",
    "    rdm = density_matrix(res, (mid))\n",
    "    q_train[i,:] = rdm |> probs\n",
    "end\n",
    "\n",
    "y_train_1_re = zeros(num_train, 2) ;\n",
    "\n",
    "for i in 1 : num_train\n",
    "    if q_train[i, 1] < 0.5\n",
    "        y_train_1_re[ i, : ] = [0 , 1]\n",
    "    else\n",
    "        y_train_1_re[ i, : ] = [1 , 0]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f74d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q_test = zeros(num_test, 2) ;\n",
    "\n",
    "for i = 1 : num_test\n",
    "    res = zero_state(num_qubit) |> test_cir_1[i]\n",
    "    rdm = density_matrix(copy(res), (mid))\n",
    "    q_test[i, :] = rdm |> probs\n",
    "end\n",
    "\n",
    "y_test_1_re = zeros(num_test, 2) ;\n",
    "\n",
    "for i in 1 : num_test\n",
    "    if q_test[i, 1] < 0.5\n",
    "        y_test_1_re[ i, : ] = [0 , 1]\n",
    "    else\n",
    "        y_test_1_re[ i, : ] = [1 , 0]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca8f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@show  sum( abs(q_train[i,1] - q_train[i,2]) >=0.2 for i in 1:num_train )\n",
    "@show  sum( (q_train[i,1] - q_train[i,2]) >=0.2 for i in 1:num_train )\n",
    "@show  sum( (q_train[i,1] - q_train[i,2]) < -0.2 for i in 1:num_train )\n",
    "@show  sum( abs(q_test[i,1] - q_test[i,2]) >=0.2 for i in 1:num_test )\n",
    "@show  sum( (q_test[i,1] - q_test[i,2]) >=0.2 for i in 1:num_test )\n",
    "@show  sum( (q_test[i,1] - q_test[i,2]) < -0.2 for i in 1:num_test ) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905f95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_test = [i for i in 1:num_test if abs(q_test[i, 1] - q_test[i, 2]) >= 0.2] ;\n",
    "index_train = [i for i in 1:num_train if abs(q_train[i, 1] - q_train[i, 2]) >= 0.2]  ;\n",
    "\n",
    "num_train_re = length(index_train) ;  num_test_re = length(index_test) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14238e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the data with abs(<Z>) > 0.1 as the dataset\n",
    "se_y_test_1_re = y_test_1_re[index_test, :]  ;\n",
    "se_y_train_1_re = y_train_1_re[index_train, :] ;\n",
    "\n",
    "se_y_train_1 = y_train_1[index_train, :] ;\n",
    "se_y_test_1 = y_test_1[index_test, :] ;\n",
    "\n",
    "quantum_trans_x_train_1 = trans_x_train_1[:, index_train] ;\n",
    "quantum_trans_x_test_1 = trans_x_test_1[:, index_test] ;\n",
    "\n",
    "classical_x_train_1 = quantum_trans_x_train_1[1 : pca_dim , :]\n",
    "classical_x_test_1 = quantum_trans_x_test_1[1 : pca_dim , :] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32bdc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(se_y_train_1[i, ] == se_y_train_1_re[i, ] for i in 1 : num_train_re )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a4451",
   "metadata": {},
   "source": [
    "## Learning using quantum neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a87838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_params  = [ 2*pi * rand() for _ in 1 : dim-(4*pca_dim-2)] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbd609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re_train_cir_1 = [ chain( circuit_encoding(num_qubit), circuit_variational(num_qubit, depth) )   for _ in 1 : num_train_re] ;\n",
    "\n",
    "re_test_cir_1  = [ chain( circuit_encoding(num_qubit), circuit_variational(num_qubit, depth) )  for _ in 1 : num_test_re] ;\n",
    "\n",
    "\n",
    "for i in 1 : num_train_re\n",
    "    dispatch!( re_train_cir_1[i], vcat( quantum_trans_x_train_1[:, i], ini_params ) ) ;\n",
    "end\n",
    "\n",
    "for i in 1 : num_test_re\n",
    "    dispatch!(re_test_cir_1[i], vcat( quantum_trans_x_test_1[:, i], ini_params )) ;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a31f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c18e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "batch_size = 25       # batch size\n",
    "lr1 = 0.05          # learning rate\n",
    "niters = 30      # number of iterations\n",
    "optim1 = Flux.NADAM(lr1) # Adam optimizer  \n",
    "\n",
    "# record the training history\n",
    "history_loss_train_1nd_1 = Float64[]\n",
    "history_acc_train_1nd_1 = Float64[]\n",
    "history_loss_test_1nd_1 = Float64[] ;\n",
    "history_acc_test_1nd_1 = Float64[] ;\n",
    "\n",
    "grad_1_history = [] ; \n",
    "\n",
    "para_1_history = [] ;\n",
    "distance_history = Float64[] ;\n",
    "\n",
    "para_1 = copy(ini_params) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72383b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2fe2e",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in 1 : niters\n",
    "    # calculate the accuracy & loss for the training & test set\n",
    "#     acc_train_1nd_1, loss_train_1nd_1 = acc_loss_evaluation(num_qubit, re_train_cir_1, se_y_train_1_re, num_train_re, mid)   \n",
    "    acc_test_1nd_1, loss_test_1nd_1 = acc_loss_evaluation(num_qubit, re_test_cir_1, se_y_test_1_re, num_test_re, mid)      \n",
    "    \n",
    "#     push!(history_loss_train_1nd_1, loss_train_1nd_1 ) ;   push!(history_acc_train_1nd_1, acc_train_1nd_1) ;\n",
    "    push!(history_loss_test_1nd_1, loss_test_1nd_1) ;   push!(history_acc_test_1nd_1, acc_test_1nd_1)\n",
    "    push!(para_1_history, para_1)\n",
    "#     push!(distance_history, norm(para_1 - ini_params ) )\n",
    "    \n",
    "#     @printf(\"\\nStep=%d, train_loss=%.3f, train_acc=%.3f\\n\", k, loss_train_1nd_1, acc_train_1nd_1)\n",
    "    @printf(\"\\nStep=%d, test_loss=%.3f, test_acc=%.3f\\n\", k, loss_test_1nd_1, acc_test_1nd_1)\n",
    "    \n",
    "    # at each training epoch, randomly choose a batch of samples from the training set\n",
    "    batch_index = randperm(num_train_re)[1 : batch_size]\n",
    "    batch_cir = re_train_cir_1[batch_index]\n",
    "    y_batch = se_y_train_1_re[batch_index,:]     \n",
    "\n",
    "    q_ = zeros(batch_size, 2) ;\n",
    "    for i = 1 : batch_size\n",
    "        q_[i, :] = density_matrix(zero_state(num_qubit) |> batch_cir[i], (mid)) |> Yao.probs\n",
    "    end\n",
    "    \n",
    "    # calculate the gradients \n",
    "    Arr = Array{Float64}(zeros(batch_size, dim))\n",
    "    for i in 1 : batch_size\n",
    "        Arr[i, :] = expect'(op0, zero_state(num_qubit)=>batch_cir[i])[2]\n",
    "    end\n",
    "    \n",
    "    C = [Arr, -Arr]\n",
    "    \n",
    "    grads = collect(mean([-sum([y_batch[i,j]*((1 ./ q_)[i,j])*batch(C)[i,:,j] for j in 1:2]) \n",
    "                       for i = 1 : batch_size]) )\n",
    "\n",
    "    push!(grad_1_history, copy(grads[4*pca_dim-1 : dim])) \n",
    "    \n",
    "    # update the parameters\n",
    "    para_1 = Flux.Optimise.update!(optim1, copy(para_1), grads[4*pca_dim-1 : dim]) ;\n",
    "    \n",
    "    # update the parameters\n",
    "    for i in 1 : num_train_re\n",
    "        dispatch!(re_train_cir_1[i], vcat( quantum_trans_x_train_1[:, i], para_1  )  )\n",
    "    end\n",
    "    for i in 1 : num_test_re\n",
    "        dispatch!(re_test_cir_1[i],  vcat( quantum_trans_x_test_1[:, i], para_1  )  )\n",
    "    end\n",
    "    \n",
    "#     if ( acc_test_1nd_1 >= 0.97  &&  loss_test_1nd_1 <= 0.53 && k >= 12) || (k >= 20)\n",
    "#         break\n",
    "#     end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff51b6",
   "metadata": {},
   "source": [
    "# Fisher information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec84dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fisher information\n",
    "fim1 = fisher(num_train_re, re_train_cir_1, se_y_train_1_re) ;\n",
    "fim1 = fim1[4*pca_dim-1 : dim] ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef37963",
   "metadata": {},
   "source": [
    "# Classical task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c3e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_2 = 500 ;\n",
    "num_test_2 = 100 ;\n",
    "\n",
    "# pca 处理\n",
    "data2 = matread(\"../dataset/MedNIST_hand_breast_wk.mat\")\n",
    "\n",
    "x_train_2 = real(data2[\"x_train\"][ :, 1 : num_train_2 ]) ; \n",
    "y_train_2 = data2[\"y_train\"][ 1 : num_train_2, : ] ;\n",
    "x_test_2 = real(data2[\"x_test\"][ :, 1 : num_test_2 ] ) ;  \n",
    "y_test_2 = data2[\"y_test\"][ 1 : num_test_2, : ]  ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7f2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_2 = hcat( x_train_2, x_test_2 ) ;\n",
    "\n",
    "# PCA \n",
    "pca_model_2 = fit(PCA, x_all_2, maxoutdim = pca_dim) ;\n",
    "trans_X_ = MultivariateStats.transform(pca_model_2, x_all_2) ;\n",
    "X_std_2 = std( trans_X_, dims = 2 ) ; trans_X_ = trans_X_ ./ X_std_2 ;  # normalize\n",
    "\n",
    "x_train_2 =  trans_X_[:, 1 : num_train_2]\n",
    "x_test_2 =  trans_X_[:, num_train_2+1 : end] ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4415c2",
   "metadata": {},
   "source": [
    "## Learning using quantum neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4322272",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_acc_train_2nd_2 = Float64[] ;   history_acc_test_2nd_2 = Float64[] ;\n",
    "history_loss_train_2nd_2 = Float64[] ;   history_loss_test_2nd_2 = Float64[] ;\n",
    "\n",
    "history_acc_test_2nd_1 = Float64[] ;   history_loss_test_2nd_1 = Float64[] ;\n",
    "\n",
    "grad_2_history = [] ;\n",
    "\n",
    "para_2_history = [] ;\n",
    "distance_history_2 = Float64[] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_2 = copy(para_1_history[end])  ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc83fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cir_2 = [chain(circuit_encoding_2(num_qubit), circuit_variational(num_qubit, depth) ) for _ in 1 : num_train_2]\n",
    "test_cir_2 = [chain(circuit_encoding_2(num_qubit), circuit_variational(num_qubit, depth) ) for _ in 1 : num_test_2];\n",
    "\n",
    "for i in 1 : num_train_2\n",
    "    dispatch!(train_cir_2[i], vcat( x_train_2[:, i], para_2 ) )\n",
    "end\n",
    "for i in 1 : num_test_2\n",
    "    dispatch!(test_cir_2[i], vcat( x_train_2[:, i], para_2 ) )\n",
    "end\n",
    "\n",
    "for i in 1 : num_train_re\n",
    "    dispatch!(re_train_cir_1[i], vcat( quantum_trans_x_train_1[:, i], para_2 ) )\n",
    "end\n",
    "for i in 1 : num_test_re\n",
    "    dispatch!(re_test_cir_1[i], vcat( quantum_trans_x_test_1[:, i], para_2 ) )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4297708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "batch_size = 25       # batch size\n",
    "lr2 = 0.05        # learning rate\n",
    "niters = 15          # number of iterations\n",
    "optim2 = Flux.NADAM(lr2) ;# Adam optimizer  \n",
    "\n",
    "lambda1 = 30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b736d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in 1 : niters\n",
    "\n",
    "#     acc_train_2nd_2, loss_train_2nd_2 = acc_loss_evaluation(num_qubit, train_cir_2, y_train_2, num_train_2, mid)\n",
    "    acc_test_2nd_2, loss_test_2nd_2 = acc_loss_evaluation(num_qubit, test_cir_2, y_test_2, num_test_2, mid)\n",
    "    acc_test_2nd_1, loss_test_2nd_1 = acc_loss_evaluation(num_qubit, re_test_cir_1, se_y_test_1_re, num_test_re, mid)\n",
    "\n",
    "#     push!(history_acc_train_2nd_2, acc_train_2nd_2) ;    push!(history_loss_train_2nd_2, loss_train_2nd_2) ;   \n",
    "    push!(history_acc_test_2nd_2, acc_test_2nd_2) ;    push!(history_loss_test_2nd_2, loss_test_2nd_2) ;   \n",
    "    \n",
    "    push!(history_acc_test_2nd_1, acc_test_2nd_1) ;    push!(history_loss_test_2nd_1, loss_test_2nd_1) ;  \n",
    "    \n",
    "    push!(para_2_history, para_2) ;     push!(distance_history_2, norm(para_2 - para_1_history[end] )    )  ;\n",
    "    \n",
    "    @printf(\"Step=%d, test_loss=%.3f,test_acc=%.3f\\n\", k, loss_test_2nd_2, acc_test_2nd_2)\n",
    "    @printf(\"task1, loss=%.3f, acc=%.3f\\n\", loss_test_2nd_1, acc_test_2nd_1)\n",
    "    \n",
    "    # at each training epoch, randomly choose a batch of samples from the training set\n",
    "    batch_index = randperm(num_train_2)[1 : batch_size] \n",
    "    batch_cir_2 = train_cir_2[batch_index]\n",
    "    y_batch_2 = y_train_2[batch_index, : ]\n",
    "\n",
    "    q_ = zeros(batch_size, 2);\n",
    "    for i = 1 : batch_size\n",
    "        q_[i, :] = density_matrix(zero_state(num_qubit) |> batch_cir_2[i], (mid)) |> Yao.probs\n",
    "    end\n",
    "    \n",
    "    # calculate the gradients w.r.t. the cross-entropy loss function\n",
    "    Arr = Array{Float64}(zeros(batch_size, nparameters(batch_cir_2[1])))\n",
    "    for i in 1 : batch_size\n",
    "        Arr[i, :] = expect'(op0, zero_state(num_qubit)=>batch_cir_2[i])[2]\n",
    "    end\n",
    "    \n",
    "    C = [Arr, -Arr]\n",
    "    \n",
    "    grads = collect(mean([-sum([y_batch_2[i,j]*((1 ./ q_)[i,j])*batch(C)[i,:,j] for j in 1 : 2]) for i = 1 : batch_size]))\n",
    "    grads = grads[pca_dim+1 : end] ;\n",
    "    \n",
    "    push!(grad_2_history, copy(grads) )\n",
    "  \n",
    "    grads = grads + lambda1 * fim1 .* (para_2 -para_1_history[end])\n",
    "    \n",
    "    # update the parameters\n",
    "    para_2 = Flux.Optimise.update!(optim2, copy(para_2), grads) ;\n",
    "    \n",
    "    # update the parameters\n",
    "    for i in 1 : num_train_2\n",
    "        dispatch!(train_cir_2[i], vcat( x_train_2[:, i], para_2 ) )\n",
    "    end\n",
    "    for i in 1 : num_test_2\n",
    "        dispatch!(test_cir_2[i], vcat( x_test_2[:, i], para_2 ) )\n",
    "    end    \n",
    "    \n",
    "    for i in 1 : num_test_re\n",
    "        dispatch!(re_test_cir_1[i], vcat( quantum_trans_x_test_1[:, i], para_2 ))\n",
    "    end       \n",
    "    \n",
    "#     if  (acc_test_2nd_2 >= 0.96 && loss_test_2nd_2 <= 0.6 && k >= 10) || (k >= 20)\n",
    "#         break\n",
    "#     end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba88830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e33a3170",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_acc_task1 = vcat(history_acc_test_1nd_1, history_acc_test_2nd_1) ;\n",
    "q_acc_task2 = vcat(history_acc_test_2nd_2) ;\n",
    "q_length_1 = length(history_acc_test_1nd_1) ;\n",
    "q_length_2 = length(history_acc_test_2nd_1) ;\n",
    "q_length_ = [q_length_1, q_length_2] ;\n",
    "\n",
    "q_loss_task1 = vcat(history_loss_test_1nd_1, history_loss_test_2nd_1) ;\n",
    "q_loss_task2 = vcat(history_loss_test_2nd_2) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32c422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot(q_acc_task1, color= :green, label = [\"task1: relabelled data\"], marker=:o, markersize = 2, lw=2, \n",
    "       legend = :bottomright, ylabel=\"Accuracy\", xlabel=\"epochs\", left = \"2cm\") \n",
    "\n",
    "Plots.plot!(q_length_[1]+1 : sum(q_length_), q_acc_task2, color= :orange, marker=:o, markersize = 2, \n",
    "        label = [\"task2: medical\"], lw=2, legend = :bottomleft) \n",
    "p = Plots.twinx() ;\n",
    "Plots.plot!(p, q_loss_task1, color= :green, label = [\"task1: relabelled data\"], marker=:star, markersize = 2, lw=2, size=(6*130, 4*130), \n",
    "                legend=:none, ylabel=\"Loss\") \n",
    "Plots.plot!(p, q_length_[1]+1 : sum(q_length_), q_loss_task2, color= :orange, marker=:star,  markersize = 2, \n",
    "        label = [\"task2: fashionmnist_17\"], lw=2, legend=:none, size=(6*100, 4*100) )\n",
    "\n",
    "fs = 10 ;\n",
    "Plots.plot!( xtickfontsize = fs, ytickfontsize= fs, xguidefontsize=fs, yguidefontsize=fs , \n",
    "                legendfontsize= fs, titlefontsize = fs, legendfont=font(8), framestyle=:box  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bfbdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197b71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd3b1eaf",
   "metadata": {},
   "source": [
    "# Learning the quantum engineered task and the classical task using                classical feedforward neural networks (FFNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649fbdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "input_size = size(classical_x_train_1, 1)\n",
    "output_size = 1\n",
    "hidden_size = 20 ;\n",
    "\n",
    "model_1 = Flux.Chain(\n",
    "    Flux.Dense(input_size, hidden_size, Flux.σ; init = Flux.randn ),\n",
    "    Flux.Dense(hidden_size, output_size, Flux.σ; init = Flux.randn ),\n",
    ")  |> Flux.f64\n",
    "\n",
    "total_params = sum(length, Flux.params(model_1)) ;\n",
    "\n",
    "@show model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = Flux.params(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6108bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss(x, y) = Flux.crossentropy(vcat(model_1(x ), 1 .- model_1(x )) , y)\n",
    "\n",
    "function acc(x, y)\n",
    "    y_pred = [ t[1] for t in argmax( vcat(model_1(x), 1 .- model_1(x)),  dims =1 ) ]\n",
    "    y_true = [ t[1] for t in argmax( y,  dims =1 ) ] ;\n",
    "\n",
    "    return sum(y_pred .== y_true) / size(x, 2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c365e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_history_loss_train_1nd_1 = Float64[]\n",
    "c_history_acc_train_1nd_1 = Float64[]\n",
    "c_history_loss_test_1nd_1 = Float64[] ;\n",
    "c_history_acc_test_1nd_1 = Float64[] ;\n",
    "\n",
    "c_para_1_history = [] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7064e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01f6b88b",
   "metadata": {},
   "source": [
    "## Learning the quantum engineered task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8017f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# relabelled data\n",
    "lr = 0.05\n",
    "opt = Flux.ADAM(lr)\n",
    "epochs = 20\n",
    "\n",
    "data_batch = Flux.Data.DataLoader((classical_x_train_1, se_y_train_1_re'), batchsize = 25, shuffle=true ) \n",
    "\n",
    "for k in 1 : epochs\n",
    "    \n",
    "#     loss_train_1nd_1 = loss(classical_x_train_1, se_y_train_1_re') ;  acc_train_1nd_1 = acc(classical_x_train_1, se_y_train_1_re')\n",
    "    loss_test_1nd_1 = loss(classical_x_test_1, se_y_test_1_re') ;   acc_test_1nd_1 = acc(classical_x_test_1, se_y_test_1_re')\n",
    "    push!( c_para_1_history, deepcopy(ps))\n",
    "        \n",
    "#     print(ps); print(\"\\n\")\n",
    "#     push!(c_history_loss_train_1nd_1, loss_train_1nd_1 ) ;   push!(c_history_acc_train_1nd_1, acc_train_1nd_1) \n",
    "    push!(c_history_loss_test_1nd_1, loss_test_1nd_1) ;   push!(c_history_acc_test_1nd_1, acc_test_1nd_1)\n",
    "    \n",
    "#     @printf(\"\\nStep=%d, train_loss=%.3f, train_acc=%.3f\\n\", k, loss_train_1nd_1, acc_train_1nd_1)\n",
    "    @printf(\"\\nStep=%d, test_loss=%.3f, test_acc=%.3f\\n\", k, loss_test_1nd_1, acc_test_1nd_1)\n",
    "    \n",
    "    Flux.train!(loss, ps, data_batch, opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_para_1_history[end]\n",
    "# ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3d931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae61b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fisher information\n",
    "g = Flux.gradient(() -> loss(classical_x_train_1[:, 1], se_y_train_1_re'[:, 1]), ps)\n",
    "fisher_t = copy(g) ;\n",
    "[ fisher_t[ ps[i] ] .= 0 for i in 1 : length(ps) ] ;\n",
    "\n",
    "for i in 1 : num_train_re\n",
    "    grads = Flux.gradient(() -> loss(classical_x_train_1[:, i], se_y_train_1_re'[:, i]), ps)\n",
    "    fisher_ = copy(grads) ;\n",
    "    [ fisher_[ ps[i] ] = fisher_[ ps[i] ] .^ 2  for i in 1 : length(ps) ] ;\n",
    "\n",
    "    fisher_t .+= fisher_\n",
    "end\n",
    "fisher_t  = fisher_t ./ num_train_re\n",
    "\n",
    "fisher_m = [];\n",
    "for n in fisher_t\n",
    "    push!(fisher_m, n)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fisher_t[ps[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vcat( [fisher_m[i] for i in 1:4]...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679cd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84fa6efe",
   "metadata": {},
   "source": [
    "## learning the classical task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.loadparams!( model_1, c_para_1_history[end] ) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9876a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda2 = 40;\n",
    "\n",
    "loss_2(x, y) = Flux.crossentropy(vcat(model_1(x ), 1 .- model_1(x )) , y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_history_acc_train_2nd_2 = Float64[] ;   c_history_acc_test_2nd_2 = Float64[] ;\n",
    "c_history_loss_train_2nd_2 = Float64[] ;   c_history_loss_test_2nd_2 = Float64[] ;\n",
    "\n",
    "c_history_acc_test_2nd_1 = Float64[] ;   c_history_loss_test_2nd_1 = Float64[] ;\n",
    "c_history_acc_train_2nd_1 = Float64[] ;   c_history_loss_train_2nd_1 = Float64[] ;\n",
    "\n",
    "c_para_2_history = [] ;\n",
    "grad_2_history = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3f826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fab68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# relabelled data\n",
    "lr2 = 0.05\n",
    "opt2 = Flux.ADAM(lr2)\n",
    "epochs = 17\n",
    "\n",
    "data_batch2 = Flux.Data.DataLoader((x_train_2, y_train_2'), batchsize = 25, shuffle=true ) \n",
    "\n",
    "for k in 1 : epochs\n",
    "   \n",
    "#     loss_train_2nd_2 = loss_2(x_train_2, y_train_2') ;   acc_train_2nd_2 = acc(x_train_2, y_train_2')\n",
    "    loss_test_2nd_2 = loss_2(x_test_2, y_test_2') ;   acc_test_2nd_2 = acc(x_test_2, y_test_2')\n",
    "    \n",
    "#     loss_train_2nd_1 = loss(classical_x_train_1, se_y_train_1_re') ;  acc_train_2nd_1 = acc(classical_x_train_1, se_y_train_1_re')\n",
    "    loss_test_2nd_1 = loss(classical_x_test_1, se_y_test_1_re') ;   acc_test_2nd_1 = acc(classical_x_test_1, se_y_test_1_re')\n",
    "    \n",
    "#     push!(c_history_acc_train_2nd_2, acc_train_2nd_2) ;    push!(c_history_loss_train_2nd_2, loss_train_2nd_2) ;   \n",
    "    push!(c_history_acc_test_2nd_2, acc_test_2nd_2) ;    push!(c_history_loss_test_2nd_2, loss_test_2nd_2) ;   \n",
    "    \n",
    "#     push!(c_history_acc_train_2nd_1, acc_train_2nd_1) ;    push!(c_history_loss_train_2nd_1, loss_train_2nd_1) ;  \n",
    "    push!(c_history_acc_test_2nd_1, acc_test_2nd_1) ;    push!(c_history_loss_test_2nd_1, loss_test_2nd_1) ;  \n",
    "    \n",
    "    push!(c_para_2_history, deepcopy(ps)) ;  \n",
    "    \n",
    "#     @printf(\"Step=%d, train_loss=%.3f, train_acc=%.3f\\n\", k, loss_train_2nd_2, acc_train_2nd_2)\n",
    "    @printf(\"Step=%d, test_loss=%.3f, test_acc=%.3f\\n\", k, loss_test_2nd_2, acc_test_2nd_2)\n",
    "    \n",
    "#     @printf(\"train_task1, loss=%.3f, acc=%.3f\\n\", loss_train_2nd_1, acc_train_2nd_1)\n",
    "    @printf(\"task1, loss=%.3f, acc=%.3f\\n\", loss_test_2nd_1, acc_test_2nd_1)\n",
    "    \n",
    "    \n",
    "    for (x, y) in data_batch2\n",
    "        grads = Flux.gradient(() -> loss_2(x, y), ps)\n",
    "        push!( grad_2_history, grads )\n",
    "        for i in 1 : length(ps)\n",
    "            grads[ps[i]] = grads[ps[i]] + lambda2 * fisher_t[ps[i]] .* (ps[i]  - c_para_1_history[end][i])\n",
    "        end\n",
    "        \n",
    "        Flux.update!(Flux.Adam(lr2), ps, grads)\n",
    "        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c09638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6090daa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de79824",
   "metadata": {},
   "source": [
    "## Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c28ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_acc_task1 = vcat(c_history_acc_test_1nd_1, c_history_acc_test_2nd_1) ;\n",
    "c_acc_task2 = vcat(c_history_acc_test_2nd_2) ;\n",
    "c_length_1 = length(c_history_acc_test_1nd_1) ;\n",
    "c_length_2 = length(c_history_acc_test_2nd_1) ;\n",
    "c_length_ = [c_length_1, c_length_2] ;\n",
    "\n",
    "c_loss_task1 = vcat(c_history_loss_test_1nd_1, c_history_loss_test_2nd_1) ;\n",
    "c_loss_task2 = vcat(c_history_loss_test_2nd_2) ;\n",
    "\n",
    "\n",
    "train_c_acc_task1 = vcat(c_history_acc_train_1nd_1, c_history_acc_train_2nd_1) ;\n",
    "train_c_acc_task2 = vcat(c_history_acc_train_2nd_2) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "matwrite(\"classical_learning_lambda_40.mat\", Dict(\n",
    "        \"c_acc_task1\" => c_acc_task1,\n",
    "        \"c_acc_task2\" => c_acc_task2,\n",
    "        \"c_length_\" => c_length_,\n",
    "        \"c_loss_task1\" => c_loss_task1, \n",
    "         \"c_loss_task2\" => c_loss_task2  )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c58016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35c0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
